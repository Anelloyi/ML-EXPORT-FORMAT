{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "import os\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import threading\n",
    "import time\n",
    "import subprocess\n",
    "import psutil\n",
    "import tempfile\n",
    "from nyoka import xgboost_to_pmml\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "import onnxmltools\n",
    "import onnxruntime as ort\n",
    "from skl2onnx.common.data_types import FloatTensorType\n",
    "import numpy as np\n",
    "from scipy.sparse import issparse\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "loaded_model = xgb.XGBClassifier()\n",
    "loaded_model.load_model('./models_train/mnist_xgboost_model.json')\n",
    "\n",
    "# 指定模型输入的数据类型\n",
    "initial_type = [('float_input', FloatTensorType([None, X_train.shape[1]]))]\n",
    "# 转换模型\n",
    "onnx_model = onnxmltools.convert_xgboost(loaded_model, initial_types=initial_type)\n",
    "onnx_model_path = 'imdb_xgboost_model.onnx'\n",
    "onnxmltools.utils.save_model(onnx_model, onnx_model_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载 MNIST 数据集\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "# 将图像数据从 3D 重塑为 2D (每个图像为一行，像素为列)\n",
    "X_train_2d = X_train.reshape(-1, 28*28)\n",
    "X_test_2d = X_test.reshape(-1, 28*28)\n",
    "\n",
    "# 将数据类型转换为 float32\n",
    "X_train_2d = X_train_2d.astype('float32') / 255\n",
    "X_test_2d = X_test_2d.astype('float32') / 255\n",
    "\n",
    "# XGBoost 对象\n",
    "model = xgb.XGBClassifier(\n",
    "    objective='multi:softmax',  # 目标函数\n",
    "    num_class=10,               # 类别数，与 MNIST 的标签数量相同\n",
    "    n_estimators=100,           # 树的个数\n",
    "    max_depth=6,                # 树的深度\n",
    "    learning_rate=0.1           # 学习速率\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 97.02%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# 训练模型\n",
    "model.fit(X_train_2d, y_train)\n",
    "\n",
    "# 预测测试集\n",
    "y_pred = model.predict(X_test_2d)\n",
    "\n",
    "# 计算准确率\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Test accuracy: {:.2f}%\".format(accuracy * 100))\n",
    "\n",
    "# loaded_model = xgb.XGBClassifier()\n",
    "# loaded_model.load_model('./models_train/mnist_xgboost_model.json')\n",
    "model.save_model('./models_train/mnist_xgboost_model.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGB Mnist JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subprocess started.\n",
      "Time taken to save model: 0.9430 seconds\n",
      "Time taken for inference on 10000 samples: 0.2236 seconds\n",
      "Subprocess finished.\n",
      "Resource monitoring finished.\n",
      "Content saved to ./mnist_models/output_xgboost/output-mnist-xgboost-json.txt\n",
      "Total energy consumption: 2980.24 mV\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import joblib\n",
    "import threading\n",
    "import psutil\n",
    "import subprocess\n",
    "import tempfile\n",
    "import os\n",
    "import re\n",
    "import xgboost as xgb\n",
    "from tensorflow.keras.datasets import mnist\n",
    "\n",
    "# 初始化全局变量\n",
    "thread_output = {}\n",
    "duration = 0\n",
    "inference_duration = 0\n",
    "\n",
    "# 定义保存模型的函数\n",
    "def save_model(stop_event, model, X_test_2d):\n",
    "    global duration\n",
    "    global inference_duration\n",
    "\n",
    "    start_time = time.time()\n",
    "    for i in range(5):\n",
    "        model.save_model('mnist_xgboost_model.json')\n",
    "    end_time = time.time()\n",
    "\n",
    "    duration = end_time - start_time\n",
    "    print(f'Time taken to save model: {duration:.4f} seconds')\n",
    "\n",
    "    start_time_inference = time.time()\n",
    "    \n",
    "    # 批量推理部分\n",
    "    batch_size = 128\n",
    "    num_samples = X_test_2d.shape[0]\n",
    "    num_batches = (num_samples + batch_size - 1) // batch_size  # 计算批次数量\n",
    "\n",
    "    for _ in range(1):  # 推理循环次数为 1\n",
    "        for batch_idx in range(num_batches):\n",
    "            batch_start = batch_idx * batch_size\n",
    "            batch_end = min(batch_start + batch_size, num_samples)\n",
    "            batch = X_test_2d[batch_start:batch_end]\n",
    "            predictions = model.predict(batch)\n",
    "            # 在此处处理预测结果，例如保存或输出\n",
    "\n",
    "    end_time_inference = time.time()\n",
    "\n",
    "    inference_duration = end_time_inference - start_time_inference\n",
    "    print(f'Time taken for inference on {num_samples} samples: {inference_duration:.4f} seconds')\n",
    "\n",
    "    stop_event.set()  # 触发停止其他线程\n",
    "\n",
    "# 监控保存模型时的资源使用率的线程函数\n",
    "def monitor_resources_during_save(stop_event):\n",
    "    cpu_usage = []\n",
    "    gpu_usage = []\n",
    "\n",
    "    while not stop_event.is_set():\n",
    "        cpu_usage.append(psutil.cpu_percent(interval=0.1))\n",
    "        try:\n",
    "            gpu_output = subprocess.check_output(['nvidia-smi', '--query-gpu=utilization.gpu', '--format=csv,noheader,nounits'])\n",
    "            gpu_usage.append(int(gpu_output.strip()))\n",
    "        except Exception as e:\n",
    "            gpu_usage.append(None)  # 如果没有GPU或nvidia-smi命令失败，则记录None\n",
    "\n",
    "    # 保存监测结果\n",
    "    thread_output['cpu_usage'] = cpu_usage\n",
    "    thread_output['gpu_usage'] = gpu_usage\n",
    "    print(\"Resource monitoring finished.\")\n",
    "\n",
    "# 运行外部脚本并捕获输出\n",
    "def run_script(stop_event):\n",
    "    try:\n",
    "        with tempfile.NamedTemporaryFile(delete=False) as tmp_file:\n",
    "            process = subprocess.Popen(['/Users/anelloyi/Desktop/run_powermetrics.sh'], stdout=tmp_file, stderr=subprocess.STDOUT, text=True)\n",
    "            print(\"Subprocess started.\")\n",
    "            while not stop_event.is_set():\n",
    "                if process.poll() is not None:  # 检查进程是否已经结束\n",
    "                    break\n",
    "            \n",
    "            if process.poll() is None:\n",
    "                process.terminate()\n",
    "                try:\n",
    "                    process.wait(timeout=0.1)\n",
    "                except subprocess.TimeoutExpired:\n",
    "                    process.kill()\n",
    "                    process.wait()\n",
    "        \n",
    "        with open(tmp_file.name, 'r') as f:\n",
    "            thread_output['powermetrics'] = f.read()\n",
    "        \n",
    "        os.remove(tmp_file.name)  # 删除临时文件\n",
    "        print(\"Subprocess finished.\")\n",
    "    except Exception as e:\n",
    "        thread_output['powermetrics'] = str(e)\n",
    "        print(\"Exception in subprocess:\", str(e))\n",
    "\n",
    "# 创建和启动线程\n",
    "stop_event = threading.Event()\n",
    "\n",
    "\n",
    "# 加载XGBoost模型\n",
    "loaded_model = xgb.XGBClassifier()\n",
    "loaded_model.load_model('./models_train/mnist_xgboost_model.json')\n",
    "\n",
    "thread1 = threading.Thread(target=save_model, args=(stop_event, loaded_model, X_test_2d))\n",
    "thread2 = threading.Thread(target=monitor_resources_during_save, args=(stop_event,))\n",
    "thread3 = threading.Thread(target=run_script, args=(stop_event,))\n",
    "thread1.start()\n",
    "thread2.start()\n",
    "thread3.start()\n",
    "\n",
    "# 等待线程完成\n",
    "thread1.join()\n",
    "thread2.join()\n",
    "thread3.join()\n",
    "\n",
    "# 输出从线程收集的数据\n",
    "content = thread_output.get('powermetrics', 'No output captured')\n",
    "# 将内容按行拆分\n",
    "lines = content.split('\\n')\n",
    "# 筛选出以 \"CPU consume\" 和 \"GPU Power\" 开头的行\n",
    "filtered_lines = [line for line in lines if line.startswith('GPU Power:') or line.startswith('CPU Power:')]\n",
    "# 将筛选后的行合并为一个字符串，每行之间用换行符分隔\n",
    "filtered_content = '\\n'.join(filtered_lines)\n",
    "\n",
    "output_file_name = './mnist_models/output_xgboost/output-mnist-xgboost-json.txt'\n",
    "with open(output_file_name, 'w') as file:\n",
    "    file.write(filtered_content)\n",
    "    file.write(f'\\nTotal Duration(s): {duration:.2f}')\n",
    "    file.write(f'\\nInference Duration(s): {inference_duration:.4f}')\n",
    "print(f\"Content saved to {output_file_name}\")\n",
    "\n",
    "filtered_lines_count = len(filtered_lines)\n",
    "#print(filtered_lines_count)\n",
    "#print(filtered_lines)\n",
    "\n",
    "duration = inference_duration\n",
    "# 确保 filtered_lines_count 不为零\n",
    "if filtered_lines_count > 0:\n",
    "    # 提取每一个采样点的数字，即CPU和GPU的具体mV\n",
    "    numbers = []\n",
    "    for line in filtered_lines:\n",
    "        match = re.search(r'[\\d.]+', line)\n",
    "        if match:\n",
    "            numbers.append(float(match.group()))\n",
    "\n",
    "    delta_time = duration * 2 / filtered_lines_count\n",
    "    numbers_scaled = [num * delta_time for num in numbers]\n",
    "    total_energy_consumption = sum(numbers_scaled)\n",
    "    print(f\"Total energy consumption: {total_energy_consumption:.2f} mV\")\n",
    "else:\n",
    "    print(\"No filtered lines to process.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGB Mnist ONNX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subprocess started.\n",
      "Time taken to save model: 0.0276 seconds\n",
      "Time taken for inference on 10000 samples: 0.2116 seconds\n",
      "Subprocess finished.\n",
      "Resource monitoring finished.\n",
      "Content saved to ./mnist_models/output_xgboost/output-mnist-xgboost-onnx.txt\n",
      "Total energy consumption: 1272.85 mV\n"
     ]
    }
   ],
   "source": [
    "import threading\n",
    "import time\n",
    "import subprocess\n",
    "import tempfile\n",
    "import os\n",
    "import re\n",
    "import psutil\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "import onnxmltools\n",
    "from onnxmltools.convert.xgboost import convert\n",
    "from skl2onnx.common.data_types import FloatTensorType\n",
    "from onnxruntime import InferenceSession\n",
    "from tensorflow.keras.datasets import mnist\n",
    "\n",
    "# 初始化全局变量\n",
    "thread_output = {}\n",
    "duration = 0\n",
    "inference_duration = 0\n",
    "\n",
    "# 定义保存模型的函数\n",
    "def save_model(stop_event, model, X_test_2d):\n",
    "    global duration\n",
    "    global inference_duration\n",
    "\n",
    "    initial_type = [('float_input', FloatTensorType([None, X_test_2d.shape[1]]))]\n",
    "    # 转换模型\n",
    "    onnx_model = convert(model, initial_types=initial_type)\n",
    "    onnx_model_path = 'mnist_xgboost_model.onnx'\n",
    "\n",
    "    start_time = time.time()\n",
    "    for i in range(1):\n",
    "        onnxmltools.utils.save_model(onnx_model, onnx_model_path)\n",
    "    end_time = time.time()\n",
    "\n",
    "    duration = end_time - start_time\n",
    "    print(f'Time taken to save model: {duration:.4f} seconds')\n",
    "\n",
    "    start_time_inference = time.time()\n",
    "    # 进行批量推理\n",
    "    session = InferenceSession(onnx_model_path)\n",
    "    input_name = session.get_inputs()[0].name\n",
    "\n",
    "    batch_size = 128\n",
    "    num_samples = X_test_2d.shape[0]\n",
    "    num_batches = (num_samples + batch_size - 1) // batch_size\n",
    "\n",
    "    for _ in range(1):  # 推理循环次数为 1\n",
    "        for batch_idx in range(num_batches):\n",
    "            batch_start = batch_idx * batch_size\n",
    "            batch_end = min(batch_start + batch_size, num_samples)\n",
    "            batch = X_test_2d[batch_start:batch_end].astype(np.float32)\n",
    "            predictions = session.run(None, {input_name: batch})\n",
    "\n",
    "    end_time_inference = time.time()\n",
    "\n",
    "    inference_duration = end_time_inference - start_time_inference\n",
    "    print(f'Time taken for inference on {num_samples} samples: {inference_duration:.4f} seconds')\n",
    "\n",
    "    stop_event.set()  # 触发停止其他线程\n",
    "\n",
    "# 监控保存模型时的资源使用率的线程函数\n",
    "def monitor_resources_during_save(stop_event):\n",
    "    cpu_usage = []\n",
    "    gpu_usage = []\n",
    "\n",
    "    while not stop_event.is_set():\n",
    "        cpu_usage.append(psutil.cpu_percent(interval=0.1))\n",
    "        try:\n",
    "            gpu_output = subprocess.check_output(['nvidia-smi', '--query-gpu=utilization.gpu', '--format=csv,noheader,nounits'])\n",
    "            gpu_usage.append(int(gpu_output.strip()))\n",
    "        except Exception as e:\n",
    "            gpu_usage.append(None)  # 如果没有GPU或nvidia-smi命令失败，则记录None\n",
    "\n",
    "    # 保存监测结果\n",
    "    thread_output['cpu_usage'] = cpu_usage\n",
    "    thread_output['gpu_usage'] = gpu_usage\n",
    "    print(\"Resource monitoring finished.\")\n",
    "\n",
    "# 运行外部脚本并捕获输出\n",
    "def run_script(stop_event):\n",
    "    try:\n",
    "        with tempfile.NamedTemporaryFile(delete=False) as tmp_file:\n",
    "            process = subprocess.Popen(['/Users/anelloyi/Desktop/run_powermetrics.sh'], stdout=tmp_file, stderr=subprocess.STDOUT, text=True)\n",
    "            print(\"Subprocess started.\")\n",
    "            while not stop_event.is_set():\n",
    "                if process.poll() is not None:  # 检查进程是否已经结束\n",
    "                    break\n",
    "            \n",
    "            if process.poll() is None:\n",
    "                process.terminate()\n",
    "                try:\n",
    "                    process.wait(timeout=0.1)\n",
    "                except subprocess.TimeoutExpired:\n",
    "                    process.kill()\n",
    "                    process.wait()\n",
    "        \n",
    "        with open(tmp_file.name, 'r') as f:\n",
    "            thread_output['powermetrics'] = f.read()\n",
    "        \n",
    "        os.remove(tmp_file.name)  # 删除临时文件\n",
    "        print(\"Subprocess finished.\")\n",
    "    except Exception as e:\n",
    "        thread_output['powermetrics'] = str(e)\n",
    "        print(\"Exception in subprocess:\", str(e))\n",
    "\n",
    "# 创建和启动线程\n",
    "stop_event = threading.Event()\n",
    "\n",
    "\n",
    "# 加载XGBoost模型\n",
    "loaded_model = xgb.XGBClassifier()\n",
    "loaded_model.load_model('./models_train/mnist_xgboost_model.json')\n",
    "\n",
    "# save_model(stop_event, loaded_model, X_test_2d)\n",
    "\n",
    "thread1 = threading.Thread(target=save_model, args=(stop_event, loaded_model, X_test_2d))\n",
    "thread2 = threading.Thread(target=monitor_resources_during_save, args=(stop_event,))\n",
    "thread3 = threading.Thread(target=run_script, args=(stop_event,))\n",
    "thread1.start()\n",
    "thread2.start()\n",
    "thread3.start()\n",
    "\n",
    "# 等待线程完成\n",
    "thread1.join()\n",
    "thread2.join()\n",
    "thread3.join()\n",
    "\n",
    "# 输出从线程收集的数据\n",
    "content = thread_output.get('powermetrics', 'No output captured')\n",
    "# 将内容按行拆分\n",
    "lines = content.split('\\n')\n",
    "# 筛选出以 \"CPU consume\" 和 \"GPU Power\" 开头的行\n",
    "filtered_lines = [line for line in lines if line.startswith('GPU Power:') or line.startswith('CPU Power:')]\n",
    "# 将筛选后的行合并为一个字符串，每行之间用换行符分隔\n",
    "filtered_content = '\\n'.join(filtered_lines)\n",
    "\n",
    "output_file_name = './mnist_models/output_xgboost/output-mnist-xgboost-onnx.txt'\n",
    "with open(output_file_name, 'w') as file:\n",
    "    file.write(filtered_content)\n",
    "    file.write(f'\\nTotal Duration(s): {duration:.2f}')\n",
    "    file.write(f'\\nInference Duration(s): {inference_duration:.4f}')\n",
    "print(f\"Content saved to {output_file_name}\")\n",
    "\n",
    "filtered_lines_count = len(filtered_lines)\n",
    "#print(filtered_lines_count)\n",
    "#print(filtered_lines)\n",
    "\n",
    "duration = inference_duration\n",
    "# 确保 filtered_lines_count 不为零\n",
    "if filtered_lines_count > 0:\n",
    "    # 提取每一个采样点的数字，即CPU和GPU的具体mV\n",
    "    numbers = []\n",
    "    for line in filtered_lines:\n",
    "        match = re.search(r'[\\d.]+', line)\n",
    "        if match:\n",
    "            numbers.append(float(match.group()))\n",
    "\n",
    "    delta_time = duration * 2 / filtered_lines_count\n",
    "    numbers_scaled = [num * delta_time for num in numbers]\n",
    "    total_energy_consumption = sum(numbers_scaled)\n",
    "    print(f\"Total energy consumption: {total_energy_consumption:.2f} mV\")\n",
    "else:\n",
    "    print(\"No filtered lines to process.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBOOST MNIST PY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import threading\n",
    "import time\n",
    "import subprocess\n",
    "import tempfile\n",
    "import os\n",
    "import re\n",
    "import psutil\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "import hummingbird.ml\n",
    "import torch\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tensorflow.keras.datasets import mnist  # 确保导入 MNIST 数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subprocess started.\n",
      "Time taken to save model: 3.7278 seconds\n",
      "Time taken for inference on 10000 samples: 0.6469 seconds\n",
      "Subprocess finished.\n",
      "Resource monitoring finished.\n",
      "Content saved to ./mnist_models/output_xgboost/output-mnist-xgboost-pth.txt\n",
      "Total energy consumption: 3509.25 mV\n"
     ]
    }
   ],
   "source": [
    "import threading\n",
    "import time\n",
    "import subprocess\n",
    "import tempfile\n",
    "import os\n",
    "import re\n",
    "import psutil\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "import torch\n",
    "import hummingbird.ml\n",
    "from tensorflow.keras.datasets import mnist\n",
    "\n",
    "# 初始化全局变量\n",
    "thread_output = {}\n",
    "duration = 0\n",
    "inference_duration = 0\n",
    "\n",
    "# 定义保存模型的函数\n",
    "def save_model(stop_event, model, X_test_2d):\n",
    "    global duration\n",
    "    global inference_duration\n",
    "\n",
    "    # 将XGBoost模型转换为PyTorch模型\n",
    "    start_time = time.time()\n",
    "    for i in range(1):\n",
    "        pytorch_model = hummingbird.ml.convert(model, 'pytorch')\n",
    "        # 保存PyTorch模型\n",
    "        torch.save(pytorch_model.model, './mnist_xgboost_model.pth')\n",
    "    end_time = time.time()\n",
    "\n",
    "    duration = end_time - start_time\n",
    "    print(f'Time taken to save model: {duration:.4f} seconds')\n",
    "\n",
    "    # 准备输入数据\n",
    "    start_time_inference = time.time()\n",
    "    # 将测试集数据转换为PyTorch张量\n",
    "    X_test_torch = torch.tensor(X_test_2d, dtype=torch.float32)\n",
    "\n",
    "    # 批量推理部分\n",
    "    batch_size = 128\n",
    "    num_samples = X_test_torch.shape[0]\n",
    "    num_batches = (num_samples + batch_size - 1) // batch_size\n",
    "\n",
    "    for _ in range(1):  # 推理循环次数为 1\n",
    "        for batch_idx in range(num_batches):\n",
    "            batch_start = batch_idx * batch_size\n",
    "            batch_end = min(batch_start + batch_size, num_samples)\n",
    "            batch = X_test_torch[batch_start:batch_end]\n",
    "            y_pred_torch = pytorch_model.predict(batch)\n",
    "\n",
    "    end_time_inference = time.time()\n",
    "\n",
    "    inference_duration = end_time_inference - start_time_inference\n",
    "    print(f'Time taken for inference on {X_test_torch.shape[0]} samples: {inference_duration:.4f} seconds')\n",
    "\n",
    "    stop_event.set()  # 触发停止其他线程\n",
    "\n",
    "# 监控保存模型时的资源使用率的线程函数\n",
    "def monitor_resources_during_save(stop_event):\n",
    "    cpu_usage = []\n",
    "    gpu_usage = []\n",
    "\n",
    "    while not stop_event.is_set():\n",
    "        cpu_usage.append(psutil.cpu_percent(interval=0.1))\n",
    "        try:\n",
    "            gpu_output = subprocess.check_output(['nvidia-smi', '--query-gpu=utilization.gpu', '--format=csv,noheader,nounits'])\n",
    "            gpu_usage.append(int(gpu_output.strip()))\n",
    "        except Exception as e:\n",
    "            gpu_usage.append(None)  # 如果没有GPU或nvidia-smi命令失败，则记录None\n",
    "\n",
    "    # 保存监测结果\n",
    "    thread_output['cpu_usage'] = cpu_usage\n",
    "    thread_output['gpu_usage'] = gpu_usage\n",
    "    print(\"Resource monitoring finished.\")\n",
    "\n",
    "# 运行外部脚本并捕获输出\n",
    "def run_script(stop_event):\n",
    "    try:\n",
    "        with tempfile.NamedTemporaryFile(delete=False) as tmp_file:\n",
    "            process = subprocess.Popen(['/Users/anelloyi/Desktop/run_powermetrics.sh'], stdout=tmp_file, stderr=subprocess.STDOUT, text=True)\n",
    "            print(\"Subprocess started.\")\n",
    "            while not stop_event.is_set():\n",
    "                if process.poll() is not None:  # 检查进程是否已经结束\n",
    "                    break\n",
    "            \n",
    "            if process.poll() is None:\n",
    "                process.terminate()\n",
    "                try:\n",
    "                    process.wait(timeout=0.1)\n",
    "                except subprocess.TimeoutExpired:\n",
    "                    process.kill()\n",
    "                    process.wait()\n",
    "        \n",
    "        with open(tmp_file.name, 'r') as f:\n",
    "            thread_output['powermetrics'] = f.read()\n",
    "        \n",
    "        os.remove(tmp_file.name)  # 删除临时文件\n",
    "        print(\"Subprocess finished.\")\n",
    "    except Exception as e:\n",
    "        thread_output['powermetrics'] = str(e)\n",
    "        print(\"Exception in subprocess:\", str(e))\n",
    "\n",
    "# 创建和启动线程\n",
    "stop_event = threading.Event()\n",
    "\n",
    "# 加载XGBoost模型\n",
    "loaded_model = xgb.XGBClassifier()\n",
    "loaded_model.load_model('./models_train/mnist_xgboost_model.json')\n",
    "\n",
    "# 启动并监控线程\n",
    "thread1 = threading.Thread(target=save_model, args=(stop_event, loaded_model, X_test_2d))\n",
    "thread2 = threading.Thread(target=monitor_resources_during_save, args=(stop_event,))\n",
    "thread3 = threading.Thread(target=run_script, args=(stop_event,))\n",
    "thread1.start()\n",
    "thread2.start()\n",
    "thread3.start()\n",
    "\n",
    "# 等待线程完成\n",
    "thread1.join()\n",
    "thread2.join()\n",
    "thread3.join()\n",
    "\n",
    "# 输出从线程收集的数据\n",
    "content = thread_output.get('powermetrics', 'No output captured')\n",
    "# 将内容按行拆分\n",
    "lines = content.split('\\n')\n",
    "# 筛选出以 \"CPU consume\" 和 \"GPU Power\" 开头的行\n",
    "filtered_lines = [line for line in lines if line.startswith('GPU Power:') or line.startswith('CPU Power:')]\n",
    "# 将筛选后的行合并为一个字符串，每行之间用换行符分隔\n",
    "filtered_content = '\\n'.join(filtered_lines)\n",
    "\n",
    "output_file_name = './mnist_models/output_xgboost/output-mnist-xgboost-pth.txt'\n",
    "with open(output_file_name, 'w') as file:\n",
    "    file.write(filtered_content)\n",
    "    file.write(f'\\nTotal Duration(s): {duration:.2f}')\n",
    "    file.write(f'\\nInference Duration(s): {inference_duration:.4f}')\n",
    "print(f\"Content saved to {output_file_name}\")\n",
    "\n",
    "filtered_lines_count = len(filtered_lines)\n",
    "# print(filtered_lines_count)\n",
    "# print(filtered_lines)\n",
    "\n",
    "duration = inference_duration\n",
    "# 确保 filtered_lines_count 不为零\n",
    "if filtered_lines_count > 0:\n",
    "    # 提取每一个采样点的数字，即CPU和GPU的具体mV\n",
    "    numbers = []\n",
    "    for line in filtered_lines:\n",
    "        match = re.search(r'[\\d.]+', line)\n",
    "        if match:\n",
    "            numbers.append(float(match.group()))\n",
    "\n",
    "    delta_time = duration * 2 / filtered_lines_count\n",
    "    numbers_scaled = [num * delta_time for num in numbers]\n",
    "    total_energy_consumption = sum(numbers_scaled)\n",
    "    print(f\"Total energy consumption: {total_energy_consumption:.2f} mV\")\n",
    "else:\n",
    "    print(\"No filtered lines to process.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.18 ('env_name')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "37cc1b05901c8571bea9fc4b42e3f528ca4394d6e6719f1b5d30d208c4a3cfc1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
