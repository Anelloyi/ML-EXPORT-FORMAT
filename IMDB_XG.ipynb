{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import threading\n",
    "import numpy as np\n",
    "import time\n",
    "import subprocess\n",
    "import os\n",
    "import psutil\n",
    "import tensorflow as tf\n",
    "import tempfile\n",
    "from tensorflow.keras.datasets import imdb\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
    "from tensorflow.keras.callbacks import LambdaCallback\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import re\n",
    "import onnxmltools\n",
    "import onnxruntime as ort\n",
    "from skl2onnx.common.data_types import FloatTensorType\n",
    "from scipy.sparse import issparse\n",
    "import hummingbird.ml\n",
    "import torch\n",
    "from sklearn2pmml import PMMLPipeline, sklearn2pmml\n",
    "from sklearn2pmml.pipeline import PMMLPipeline\n",
    "from pypmml import Model\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from xgboost import XGBClassifier\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载 IMDB 数据集\n",
    "max_features = 20000  # 使用的单词数量\n",
    "maxlen = 100  # 每条评论的最大长度\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words=max_features)\n",
    "\n",
    "# 将序列转换为文本\n",
    "word_index = imdb.get_word_index()\n",
    "index_word = {v: k for k, v in word_index.items()}\n",
    "\n",
    "def sequences_to_texts(sequences):\n",
    "    return [' '.join([index_word.get(i - 3, '?') for i in seq]) for seq in sequences]\n",
    "\n",
    "X_train_text = sequences_to_texts(X_train)\n",
    "X_test_text = sequences_to_texts(X_test)\n",
    "\n",
    "# 使用TF-IDF向量化文本数据\n",
    "vectorizer = TfidfVectorizer(max_features=max_features)\n",
    "X_train_tfidf = vectorizer.fit_transform(X_train_text)\n",
    "X_test_tfidf = vectorizer.transform(X_test_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 83.10%\n"
     ]
    }
   ],
   "source": [
    "## 模型训练\n",
    "# XGBoost 对象\n",
    "model = xgb.XGBClassifier(\n",
    "    objective='binary:logistic',  # 目标函数，二分类问题使用'logistic'目标函数\n",
    "    n_estimators=100,             # 树的个数\n",
    "    max_depth=6,                  # 树的深度\n",
    "    learning_rate=0.1             # 学习速率\n",
    ")\n",
    "\n",
    "# 训练模型\n",
    "model.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# 预测测试集\n",
    "y_pred = model.predict(X_test_tfidf)\n",
    "\n",
    "# 计算准确率\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Test accuracy: {:.2f}%\".format(accuracy * 100))\n",
    "\n",
    "# 保存模型到本地文件\n",
    "model.save_model('./models_train/imdb_xgboost_model.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### imdb xg json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subprocess started.\n",
      "Time taken to save model: 1.3039 seconds\n",
      "Time taken for inference on 10000 samples: 2.0365 seconds\n",
      "Subprocess finished.\n",
      "Resource monitoring finished.\n",
      "Content saved to ./imbd_models/output_xgboost/output-imdb-xgboost-json.txt\n",
      "328\n",
      "['CPU Power: 15688 mW', 'GPU Power: 0 mW', 'CPU Power: 13204 mW', 'GPU Power: 65 mW', 'CPU Power: 15592 mW', 'GPU Power: 0 mW', 'CPU Power: 17213 mW', 'GPU Power: 0 mW', 'CPU Power: 17244 mW', 'GPU Power: 0 mW', 'CPU Power: 20059 mW', 'GPU Power: 0 mW', 'CPU Power: 21972 mW', 'GPU Power: 0 mW', 'CPU Power: 20838 mW', 'GPU Power: 67 mW', 'CPU Power: 19929 mW', 'GPU Power: 68 mW', 'CPU Power: 19641 mW', 'GPU Power: 0 mW', 'CPU Power: 21909 mW', 'GPU Power: 0 mW', 'CPU Power: 23434 mW', 'GPU Power: 0 mW', 'CPU Power: 14535 mW', 'GPU Power: 129 mW', 'CPU Power: 8179 mW', 'GPU Power: 190 mW', 'CPU Power: 10152 mW', 'GPU Power: 68 mW', 'CPU Power: 7763 mW', 'GPU Power: 62 mW', 'CPU Power: 6515 mW', 'GPU Power: 0 mW', 'CPU Power: 11506 mW', 'GPU Power: 59 mW', 'CPU Power: 14257 mW', 'GPU Power: 307 mW', 'CPU Power: 12975 mW', 'GPU Power: 187 mW', 'CPU Power: 14519 mW', 'GPU Power: 0 mW', 'CPU Power: 17572 mW', 'GPU Power: 0 mW', 'CPU Power: 14283 mW', 'GPU Power: 0 mW', 'CPU Power: 9273 mW', 'GPU Power: 112 mW', 'CPU Power: 3382 mW', 'GPU Power: 169 mW', 'CPU Power: 5014 mW', 'GPU Power: 58 mW', 'CPU Power: 4568 mW', 'GPU Power: 0 mW', 'CPU Power: 3989 mW', 'GPU Power: 116 mW', 'CPU Power: 11542 mW', 'GPU Power: 178 mW', 'CPU Power: 13505 mW', 'GPU Power: 61 mW', 'CPU Power: 14070 mW', 'GPU Power: 0 mW', 'CPU Power: 12982 mW', 'GPU Power: 0 mW', 'CPU Power: 13772 mW', 'GPU Power: 0 mW', 'CPU Power: 13422 mW', 'GPU Power: 0 mW', 'CPU Power: 9684 mW', 'GPU Power: 0 mW', 'CPU Power: 3023 mW', 'GPU Power: 0 mW', 'CPU Power: 5281 mW', 'GPU Power: 0 mW', 'CPU Power: 3984 mW', 'GPU Power: 0 mW', 'CPU Power: 3016 mW', 'GPU Power: 0 mW', 'CPU Power: 9862 mW', 'GPU Power: 0 mW', 'CPU Power: 13987 mW', 'GPU Power: 0 mW', 'CPU Power: 15068 mW', 'GPU Power: 0 mW', 'CPU Power: 14516 mW', 'GPU Power: 60 mW', 'CPU Power: 13079 mW', 'GPU Power: 0 mW', 'CPU Power: 13109 mW', 'GPU Power: 0 mW', 'CPU Power: 20796 mW', 'GPU Power: 0 mW', 'CPU Power: 14318 mW', 'GPU Power: 0 mW', 'CPU Power: 3495 mW', 'GPU Power: 0 mW', 'CPU Power: 8286 mW', 'GPU Power: 0 mW', 'CPU Power: 6479 mW', 'GPU Power: 126 mW', 'CPU Power: 3035 mW', 'GPU Power: 0 mW', 'CPU Power: 9641 mW', 'GPU Power: 172 mW', 'CPU Power: 27463 mW', 'GPU Power: 0 mW', 'CPU Power: 20402 mW', 'GPU Power: 0 mW', 'CPU Power: 25603 mW', 'GPU Power: 0 mW', 'CPU Power: 21205 mW', 'GPU Power: 118 mW', 'CPU Power: 24913 mW', 'GPU Power: 0 mW', 'CPU Power: 22562 mW', 'GPU Power: 169 mW', 'CPU Power: 8504 mW', 'GPU Power: 51 mW', 'CPU Power: 3042 mW', 'GPU Power: 60 mW', 'CPU Power: 10985 mW', 'GPU Power: 0 mW', 'CPU Power: 3374 mW', 'GPU Power: 0 mW', 'CPU Power: 5281 mW', 'GPU Power: 0 mW', 'CPU Power: 15019 mW', 'GPU Power: 121 mW', 'CPU Power: 24978 mW', 'GPU Power: 0 mW', 'CPU Power: 21510 mW', 'GPU Power: 235 mW', 'CPU Power: 26338 mW', 'GPU Power: 57 mW', 'CPU Power: 22050 mW', 'GPU Power: 0 mW', 'CPU Power: 24072 mW', 'GPU Power: 0 mW', 'CPU Power: 6112 mW', 'GPU Power: 0 mW', 'CPU Power: 3137 mW', 'GPU Power: 0 mW', 'CPU Power: 6868 mW', 'GPU Power: 120 mW', 'CPU Power: 3728 mW', 'GPU Power: 0 mW', 'CPU Power: 6221 mW', 'GPU Power: 0 mW', 'CPU Power: 20459 mW', 'GPU Power: 188 mW', 'CPU Power: 24068 mW', 'GPU Power: 66 mW', 'CPU Power: 21777 mW', 'GPU Power: 0 mW', 'CPU Power: 24039 mW', 'GPU Power: 0 mW', 'CPU Power: 21142 mW', 'GPU Power: 0 mW', 'CPU Power: 24712 mW', 'GPU Power: 123 mW', 'CPU Power: 9029 mW', 'GPU Power: 130 mW', 'CPU Power: 2954 mW', 'GPU Power: 0 mW', 'CPU Power: 5560 mW', 'GPU Power: 247 mW', 'CPU Power: 2946 mW', 'GPU Power: 0 mW', 'CPU Power: 4687 mW', 'GPU Power: 0 mW', 'CPU Power: 19504 mW', 'GPU Power: 0 mW', 'CPU Power: 23067 mW', 'GPU Power: 0 mW', 'CPU Power: 21609 mW', 'GPU Power: 0 mW', 'CPU Power: 23064 mW', 'GPU Power: 0 mW', 'CPU Power: 23140 mW', 'GPU Power: 0 mW', 'CPU Power: 20347 mW', 'GPU Power: 0 mW', 'CPU Power: 6155 mW', 'GPU Power: 0 mW', 'CPU Power: 2899 mW', 'GPU Power: 0 mW', 'CPU Power: 5327 mW', 'GPU Power: 0 mW', 'CPU Power: 3207 mW', 'GPU Power: 0 mW', 'CPU Power: 6806 mW', 'GPU Power: 0 mW', 'CPU Power: 24216 mW', 'GPU Power: 0 mW', 'CPU Power: 19428 mW', 'GPU Power: 0 mW', 'CPU Power: 22106 mW', 'GPU Power: 0 mW', 'CPU Power: 23833 mW', 'GPU Power: 0 mW', 'CPU Power: 21321 mW', 'GPU Power: 0 mW', 'CPU Power: 24504 mW', 'GPU Power: 123 mW', 'CPU Power: 3740 mW', 'GPU Power: 0 mW', 'CPU Power: 3586 mW', 'GPU Power: 0 mW', 'CPU Power: 5513 mW', 'GPU Power: 172 mW', 'CPU Power: 3015 mW', 'GPU Power: 0 mW', 'CPU Power: 10014 mW', 'GPU Power: 0 mW', 'CPU Power: 24842 mW', 'GPU Power: 121 mW', 'CPU Power: 21291 mW', 'GPU Power: 0 mW', 'CPU Power: 24304 mW', 'GPU Power: 238 mW', 'CPU Power: 22898 mW', 'GPU Power: 0 mW', 'CPU Power: 24099 mW', 'GPU Power: 0 mW', 'CPU Power: 15048 mW', 'GPU Power: 106 mW', 'CPU Power: 3164 mW', 'GPU Power: 0 mW', 'CPU Power: 6070 mW', 'GPU Power: 0 mW', 'CPU Power: 4749 mW', 'GPU Power: 130 mW', 'CPU Power: 6579 mW', 'GPU Power: 0 mW', 'CPU Power: 23854 mW', 'GPU Power: 154 mW', 'CPU Power: 18551 mW', 'GPU Power: 0 mW', 'CPU Power: 25576 mW', 'GPU Power: 0 mW', 'CPU Power: 19197 mW', 'GPU Power: 0 mW', 'CPU Power: 25533 mW', 'GPU Power: 0 mW', 'CPU Power: 13389 mW', 'GPU Power: 0 mW', 'CPU Power: 3950 mW', 'GPU Power: 118 mW', 'CPU Power: 4423 mW', 'GPU Power: 0 mW', 'CPU Power: 4286 mW', 'GPU Power: 241 mW', 'CPU Power: 3605 mW', 'GPU Power: 122 mW', 'CPU Power: 8222 mW', 'GPU Power: 0 mW', 'CPU Power: 23745 mW', 'GPU Power: 0 mW', 'CPU Power: 21541 mW', 'GPU Power: 0 mW', 'CPU Power: 24727 mW', 'GPU Power: 0 mW', 'CPU Power: 23236 mW', 'GPU Power: 0 mW', 'CPU Power: 22446 mW', 'GPU Power: 0 mW', 'CPU Power: 24090 mW', 'GPU Power: 122 mW', 'CPU Power: 18910 mW', 'GPU Power: 58 mW', 'CPU Power: 14829 mW', 'GPU Power: 0 mW', 'CPU Power: 9653 mW', 'GPU Power: 169 mW', 'CPU Power: 13440 mW', 'GPU Power: 178 mW', 'CPU Power: 8046 mW', 'GPU Power: 0 mW', 'CPU Power: 18080 mW', 'GPU Power: 233 mW', 'CPU Power: 26829 mW', 'GPU Power: 0 mW', 'CPU Power: 19476 mW', 'GPU Power: 54 mW', 'CPU Power: 25268 mW', 'GPU Power: 0 mW', 'CPU Power: 23404 mW', 'GPU Power: 218 mW', 'CPU Power: 24954 mW', 'GPU Power: 0 mW', 'CPU Power: 26592 mW', 'GPU Power: 0 mW', 'CPU Power: 24405 mW', 'GPU Power: 178 mW', 'CPU Power: 22564 mW', 'GPU Power: 0 mW', 'CPU Power: 24745 mW', 'GPU Power: 0 mW', 'CPU Power: 24687 mW', 'GPU Power: 0 mW', 'CPU Power: 20002 mW', 'GPU Power: 0 mW', 'CPU Power: 21202 mW', 'GPU Power: 0 mW', 'CPU Power: 24540 mW', 'GPU Power: 0 mW', 'CPU Power: 27069 mW', 'GPU Power: 0 mW', 'CPU Power: 25515 mW', 'GPU Power: 0 mW', 'CPU Power: 26283 mW', 'GPU Power: 0 mW', 'CPU Power: 25801 mW', 'GPU Power: 0 mW', 'CPU Power: 24981 mW', 'GPU Power: 0 mW', 'CPU Power: 19805 mW', 'GPU Power: 55 mW', 'CPU Power: 14448 mW', 'GPU Power: 0 mW', 'CPU Power: 20627 mW', 'GPU Power: 294 mW', 'CPU Power: 14922 mW', 'GPU Power: 0 mW', 'CPU Power: 15160 mW', 'GPU Power: 249 mW', 'CPU Power: 19733 mW', 'GPU Power: 112 mW']\n",
      "Total energy consumption: 20059.55 mV\n"
     ]
    }
   ],
   "source": [
    "# 初始化全局变量\n",
    "thread_output = {}\n",
    "duration = 0\n",
    "inference_duration = 0\n",
    "\n",
    "# 定义保存模型的函数\n",
    "def save_model(stop_event, model, X_test_tfidf):\n",
    "    global duration\n",
    "    global inference_duration\n",
    "\n",
    "    start_time = time.time()\n",
    "    for i in range(5):\n",
    "        model.save_model('imdb_xgboost_model.json')\n",
    "    end_time = time.time()\n",
    "\n",
    "    duration = end_time - start_time\n",
    "    print(f'Time taken to save model: {duration:.4f} seconds')\n",
    "\n",
    "    # 确保输入数据格式正确\n",
    "    X_test_sample = X_test_tfidf[:10000]\n",
    "\n",
    "    start_time_inference = time.time()\n",
    "    # 进行推理\n",
    "    for i in range(32): # 1*10\n",
    "        model.predict(X_test_tfidf)\n",
    "    end_time_inference = time.time()\n",
    "\n",
    "    inference_duration = end_time_inference - start_time_inference\n",
    "    print(f'Time taken for inference on {X_test_sample.shape[0]} samples: {inference_duration:.4f} seconds')\n",
    "\n",
    "    stop_event.set()  # 触发停止其他线程\n",
    "\n",
    "# 监控保存模型时的资源使用率的线程函数\n",
    "def monitor_resources_during_save(stop_event):\n",
    "    cpu_usage = []\n",
    "    gpu_usage = []\n",
    "\n",
    "    while not stop_event.is_set():\n",
    "        cpu_usage.append(psutil.cpu_percent(interval=0.1))\n",
    "        try:\n",
    "            gpu_output = subprocess.check_output(['nvidia-smi', '--query-gpu=utilization.gpu', '--format=csv,noheader,nounits'])\n",
    "            gpu_usage.append(int(gpu_output.strip()))\n",
    "        except Exception as e:\n",
    "            gpu_usage.append(None)  # 如果没有GPU或nvidia-smi命令失败，则记录None\n",
    "\n",
    "    # 保存监测结果\n",
    "    thread_output['cpu_usage'] = cpu_usage\n",
    "    thread_output['gpu_usage'] = gpu_usage\n",
    "    print(\"Resource monitoring finished.\")\n",
    "\n",
    "# 运行外部脚本并捕获输出\n",
    "def run_script(stop_event):\n",
    "    try:\n",
    "        with tempfile.NamedTemporaryFile(delete=False) as tmp_file:\n",
    "            process = subprocess.Popen(['/Users/anelloyi/Desktop/run_powermetrics.sh'], stdout=tmp_file, stderr=subprocess.STDOUT, text=True)\n",
    "            print(\"Subprocess started.\")\n",
    "            while not stop_event.is_set():\n",
    "                if process.poll() is not None:  # 检查进程是否已经结束\n",
    "                    break\n",
    "            \n",
    "            if process.poll() is None:\n",
    "                process.terminate()\n",
    "                try:\n",
    "                    process.wait(timeout=0.1)\n",
    "                except subprocess.TimeoutExpired:\n",
    "                    process.kill()\n",
    "                    process.wait()\n",
    "        \n",
    "        with open(tmp_file.name, 'r') as f:\n",
    "            thread_output['powermetrics'] = f.read()\n",
    "        \n",
    "        os.remove(tmp_file.name)  # 删除临时文件\n",
    "        print(\"Subprocess finished.\")\n",
    "    except Exception as e:\n",
    "        thread_output['powermetrics'] = str(e)\n",
    "        print(\"Exception in subprocess:\", str(e))\n",
    "\n",
    "# 创建和启动线程\n",
    "stop_event = threading.Event()\n",
    "\n",
    "# 加载XGBoost模型\n",
    "loaded_model = xgb.XGBClassifier()\n",
    "loaded_model.load_model('./models_train/imdb_xgboost_model.json')\n",
    "\n",
    "# save_model(stop_event, loaded_model, X_test_tfidf)\n",
    "\n",
    "thread1 = threading.Thread(target=save_model, args=(stop_event, loaded_model, X_test_tfidf))\n",
    "thread2 = threading.Thread(target=monitor_resources_during_save, args=(stop_event,))\n",
    "thread3 = threading.Thread(target=run_script, args=(stop_event,))\n",
    "thread1.start()\n",
    "thread2.start()\n",
    "thread3.start()\n",
    "\n",
    "# 等待线程完成\n",
    "thread1.join()\n",
    "thread2.join()\n",
    "thread3.join()\n",
    "\n",
    "# 输出从线程收集的数据\n",
    "content = thread_output.get('powermetrics', 'No output captured')\n",
    "# 将内容按行拆分\n",
    "lines = content.split('\\n')\n",
    "# 筛选出以 \"CPU consume\" 和 \"GPU Power\" 开头的行\n",
    "filtered_lines = [line for line in lines if line.startswith('GPU Power:') or line.startswith('CPU Power:')]\n",
    "# 将筛选后的行合并为一个字符串，每行之间用换行符分隔\n",
    "filtered_content = '\\n'.join(filtered_lines)\n",
    "\n",
    "output_file_name = './imbd_models/output_xgboost/output-imdb-xgboost-json.txt'\n",
    "with open(output_file_name, 'w') as file:\n",
    "    file.write(filtered_content)\n",
    "    file.write(f'\\nTotal Duration(s): {duration:.2f}')\n",
    "    file.write(f'\\nInference Duration(s): {inference_duration:.4f}')\n",
    "print(f\"Content saved to {output_file_name}\")\n",
    "\n",
    "filtered_lines_count = len(filtered_lines)\n",
    "#print(filtered_lines_count)\n",
    "#print(filtered_lines)\n",
    "\n",
    "# 确保 filtered_lines_count 不为零\n",
    "if filtered_lines_count > 0:\n",
    "    # 提取每一个采样点的数字，即CPU和GPU的具体mV\n",
    "    numbers = []\n",
    "    for line in filtered_lines:\n",
    "        match = re.search(r'[\\d.]+', line)\n",
    "        if match:\n",
    "            numbers.append(float(match.group()))\n",
    "\n",
    "    delta_time = duration * 2 / filtered_lines_count\n",
    "    numbers_scaled = [num * delta_time for num in numbers]\n",
    "    total_energy_consumption = sum(numbers_scaled)\n",
    "    print(f\"Total energy consumption: {total_energy_consumption:.2f} mV\")\n",
    "else:\n",
    "    print(\"No filtered lines to process.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subprocess started.\n",
      "Time taken to save model: 0.9856 seconds\n",
      "Time taken for inference on 10000 samples: 0.1916 seconds\n",
      "Subprocess finished.\n",
      "Resource monitoring finished.\n",
      "Content saved to ./imbd_models/output_xgboost/output-imdb-xgboost-json.txt\n",
      "Total energy consumption: 2074.66 mV\n"
     ]
    }
   ],
   "source": [
    "import threading\n",
    "import time\n",
    "import subprocess\n",
    "import tempfile\n",
    "import os\n",
    "import re\n",
    "import psutil\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from tensorflow.keras.datasets import imdb\n",
    "\n",
    "# 初始化全局变量\n",
    "thread_output = {}\n",
    "duration = 0\n",
    "inference_duration = 0\n",
    "\n",
    "# 定义保存模型的函数\n",
    "def save_model(stop_event, model, X_test_tfidf):\n",
    "    global duration\n",
    "    global inference_duration\n",
    "\n",
    "    start_time = time.time()\n",
    "    for i in range(50):\n",
    "        model.save_model('imdb_xgboost_model.json')\n",
    "    end_time = time.time()\n",
    "\n",
    "    duration = end_time - start_time\n",
    "    print(f'Time taken to save model: {duration:.4f} seconds')\n",
    "\n",
    "    # 确保输入数据格式正确\n",
    "    X_test_sample = X_test_tfidf[:10000]\n",
    "\n",
    "    start_time_inference = time.time()\n",
    "    # 批量推理部分\n",
    "    batch_size = 128\n",
    "    num_samples = X_test_sample.shape[0]\n",
    "    num_batches = (num_samples + batch_size - 1) // batch_size\n",
    "\n",
    "    for _ in range(1):  # 推理\n",
    "        for batch_idx in range(num_batches):\n",
    "            batch_start = batch_idx * batch_size\n",
    "            batch_end = min(batch_start + batch_size, num_samples)\n",
    "            batch = X_test_sample[batch_start:batch_end]\n",
    "            predictions = model.predict(batch)\n",
    "            # 在此处处理预测结果，例如保存或输出\n",
    "\n",
    "    end_time_inference = time.time()\n",
    "\n",
    "    inference_duration = end_time_inference - start_time_inference\n",
    "    print(f'Time taken for inference on {X_test_sample.shape[0]} samples: {inference_duration:.4f} seconds')\n",
    "\n",
    "    stop_event.set()  # 触发停止其他线程\n",
    "\n",
    "# 监控保存模型时的资源使用率的线程函数\n",
    "def monitor_resources_during_save(stop_event):\n",
    "    cpu_usage = []\n",
    "    gpu_usage = []\n",
    "\n",
    "    while not stop_event.is_set():\n",
    "        cpu_usage.append(psutil.cpu_percent(interval=0.1))\n",
    "        try:\n",
    "            gpu_output = subprocess.check_output(['nvidia-smi', '--query-gpu=utilization.gpu', '--format=csv,noheader,nounits'])\n",
    "            gpu_usage.append(int(gpu_output.strip()))\n",
    "        except Exception as e:\n",
    "            gpu_usage.append(None)  # 如果没有GPU或nvidia-smi命令失败，则记录None\n",
    "\n",
    "    # 保存监测结果\n",
    "    thread_output['cpu_usage'] = cpu_usage\n",
    "    thread_output['gpu_usage'] = gpu_usage\n",
    "    print(\"Resource monitoring finished.\")\n",
    "\n",
    "# 运行外部脚本并捕获输出\n",
    "def run_script(stop_event):\n",
    "    try:\n",
    "        with tempfile.NamedTemporaryFile(delete=False) as tmp_file:\n",
    "            process = subprocess.Popen(['/Users/anelloyi/Desktop/run_powermetrics.sh'], stdout=tmp_file, stderr=subprocess.STDOUT, text=True)\n",
    "            print(\"Subprocess started.\")\n",
    "            while not stop_event.is_set():\n",
    "                if process.poll() is not None:  # 检查进程是否已经结束\n",
    "                    break\n",
    "            \n",
    "            if process.poll() is None:\n",
    "                process.terminate()\n",
    "                try:\n",
    "                    process.wait(timeout=0.1)\n",
    "                except subprocess.TimeoutExpired:\n",
    "                    process.kill()\n",
    "                    process.wait()\n",
    "        \n",
    "        with open(tmp_file.name, 'r') as f:\n",
    "            thread_output['powermetrics'] = f.read()\n",
    "        \n",
    "        os.remove(tmp_file.name)  # 删除临时文件\n",
    "        print(\"Subprocess finished.\")\n",
    "    except Exception as e:\n",
    "        thread_output['powermetrics'] = str(e)\n",
    "        print(\"Exception in subprocess:\", str(e))\n",
    "\n",
    "# 创建和启动线程\n",
    "stop_event = threading.Event()\n",
    "\n",
    "# 加载IMDB数据集并进行TF-IDF向量化\n",
    "max_features = 20000  # 使用的单词数量\n",
    "(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words=max_features)\n",
    "\n",
    "# 将序列转换为文本\n",
    "word_index = imdb.get_word_index()\n",
    "index_word = {v: k for k, v in word_index.items()}\n",
    "\n",
    "def sequences_to_texts(sequences):\n",
    "    return [' '.join([index_word.get(i - 3, '?') for i in seq]) for seq in sequences]\n",
    "\n",
    "X_train_text = sequences_to_texts(X_train)\n",
    "X_test_text = sequences_to_texts(X_test)\n",
    "\n",
    "# 使用TF-IDF向量化文本数据\n",
    "vectorizer = TfidfVectorizer(max_features=max_features)\n",
    "X_train_tfidf = vectorizer.fit_transform(X_train_text)\n",
    "X_test_tfidf = vectorizer.transform(X_test_text)\n",
    "\n",
    "# 加载XGBoost模型\n",
    "loaded_model = xgb.XGBClassifier()\n",
    "loaded_model.load_model('./models_train/imdb_xgboost_model.json')\n",
    "\n",
    "# save_model(stop_event, loaded_model, X_test_tfidf)\n",
    "\n",
    "thread1 = threading.Thread(target=save_model, args=(stop_event, loaded_model, X_test_tfidf))\n",
    "thread2 = threading.Thread(target=monitor_resources_during_save, args=(stop_event,))\n",
    "thread3 = threading.Thread(target=run_script, args=(stop_event,))\n",
    "thread1.start()\n",
    "thread2.start()\n",
    "thread3.start()\n",
    "\n",
    "# 等待线程完成\n",
    "thread1.join()\n",
    "thread2.join()\n",
    "thread3.join()\n",
    "\n",
    "# 输出从线程收集的数据\n",
    "content = thread_output.get('powermetrics', 'No output captured')\n",
    "# 将内容按行拆分\n",
    "lines = content.split('\\n')\n",
    "# 筛选出以 \"CPU consume\" 和 \"GPU Power\" 开头的行\n",
    "filtered_lines = [line for line in lines if line.startswith('GPU Power:') or line.startswith('CPU Power:')]\n",
    "# 将筛选后的行合并为一个字符串，每行之间用换行符分隔\n",
    "filtered_content = '\\n'.join(filtered_lines)\n",
    "\n",
    "output_file_name = './imbd_models/output_xgboost/output-imdb-xgboost-json.txt'\n",
    "with open(output_file_name, 'w') as file:\n",
    "    file.write(filtered_content)\n",
    "    file.write(f'\\nTotal Duration(s): {duration:.2f}')\n",
    "    file.write(f'\\nInference Duration(s): {inference_duration:.4f}')\n",
    "print(f\"Content saved to {output_file_name}\")\n",
    "\n",
    "filtered_lines_count = len(filtered_lines)\n",
    "#print(filtered_lines_count)\n",
    "#print(filtered_lines)\n",
    "\n",
    "duration = inference_duration\n",
    "# 确保 filtered_lines_count 不为零\n",
    "if filtered_lines_count > 0:\n",
    "    # 提取每一个采样点的数字，即CPU和GPU的具体mV\n",
    "    numbers = []\n",
    "    for line in filtered_lines:\n",
    "        match = re.search(r'[\\d.]+', line)\n",
    "        if match:\n",
    "            numbers.append(float(match.group()))\n",
    "\n",
    "    delta_time = duration * 2 / filtered_lines_count\n",
    "    numbers_scaled = [num * delta_time for num in numbers]\n",
    "    total_energy_consumption = sum(numbers_scaled)\n",
    "    print(f\"Total energy consumption: {total_energy_consumption:.2f} mV\")\n",
    "else:\n",
    "    print(\"No filtered lines to process.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### imdb xg onnx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subprocess started.\n",
      "Time taken to save model: 0.5587 seconds\n",
      "Time taken for inference on 10000 samples: 0.1426 seconds\n",
      "Subprocess finished.\n",
      "Resource monitoring finished.\n",
      "Content saved to ./imbd_models/output_xgboost/output-imdb-xgboost-onnx.txt\n",
      "Total energy consumption: 1084.31 mV\n"
     ]
    }
   ],
   "source": [
    "import threading\n",
    "import time\n",
    "import subprocess\n",
    "import tempfile\n",
    "import os\n",
    "import re\n",
    "import psutil\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "import onnxruntime as ort\n",
    "import onnxmltools\n",
    "from skl2onnx.common.data_types import FloatTensorType\n",
    "from scipy.sparse import issparse\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from tensorflow.keras.datasets import imdb\n",
    "\n",
    "# 初始化全局变量\n",
    "thread_output = {}\n",
    "duration = 0\n",
    "inference_duration = 0\n",
    "\n",
    "# 定义保存模型的函数\n",
    "def save_model(stop_event, model, X_test_tfidf):\n",
    "    global duration\n",
    "    global inference_duration\n",
    "\n",
    "    # 定义ONNX转换器的输入类型\n",
    "    initial_type = [('float_input', FloatTensorType([None, max_features]))]\n",
    "\n",
    "    start_time = time.time()\n",
    "    # 将 XGBoost 模型转换为 ONNX 格式\n",
    "    for i in range(1):\n",
    "        onnx_model = onnxmltools.convert_xgboost(model, initial_types=initial_type)\n",
    "        onnx_model_path = 'imdb_xgboost_model.onnx'\n",
    "        onnxmltools.utils.save_model(onnx_model, onnx_model_path)\n",
    "    end_time = time.time()\n",
    "\n",
    "    duration = end_time - start_time\n",
    "    print(f'Time taken to save model: {duration:.4f} seconds')\n",
    "\n",
    "    ort_session = ort.InferenceSession(onnx_model_path)\n",
    "    # 准备输入数据\n",
    "    def to_numpy(matrix):\n",
    "        if issparse(matrix):\n",
    "            return matrix.todense().astype(np.float32)\n",
    "        return matrix.astype(np.float32)\n",
    "    \n",
    "    X_test_numpy = to_numpy(X_test_tfidf)\n",
    "    \n",
    "    # 确保输入数据的形状与模型期望的一致\n",
    "    if X_test_numpy.shape[1] < max_features:\n",
    "        padding = np.zeros((X_test_numpy.shape[0], max_features - X_test_numpy.shape[1]), dtype=np.float32)\n",
    "        X_test_numpy = np.hstack((X_test_numpy, padding))\n",
    "    elif X_test_numpy.shape[1] > max_features:\n",
    "        X_test_numpy = X_test_numpy[:, :max_features]\n",
    "\n",
    "    input_name = ort_session.get_inputs()[0].name\n",
    "    output_name = ort_session.get_outputs()[0].name\n",
    "\n",
    "    # 确保输入数据格式正确\n",
    "    X_test_sample = X_test_numpy[:10000]\n",
    "\n",
    "    start_time_inference = time.time()\n",
    "    \n",
    "    # 批量推理部分\n",
    "    batch_size = 128\n",
    "    num_samples = X_test_sample.shape[0]\n",
    "    num_batches = (num_samples + batch_size - 1) // batch_size\n",
    "\n",
    "    for _ in range(1):  # 推理循环次数为 1\n",
    "        for batch_idx in range(num_batches):\n",
    "            batch_start = batch_idx * batch_size\n",
    "            batch_end = min(batch_start + batch_size, num_samples)\n",
    "            batch = X_test_sample[batch_start:batch_end]\n",
    "            input_data = {input_name: batch}\n",
    "            pred_onnx = ort_session.run([output_name], input_data)[0]\n",
    "\n",
    "    end_time_inference = time.time()\n",
    "\n",
    "    inference_duration = end_time_inference - start_time_inference\n",
    "    print(f'Time taken for inference on {X_test_sample.shape[0]} samples: {inference_duration:.4f} seconds')\n",
    "\n",
    "    stop_event.set()  # 触发停止其他线程\n",
    "\n",
    "# 监控保存模型时的资源使用率的线程函数\n",
    "def monitor_resources_during_save(stop_event):\n",
    "    cpu_usage = []\n",
    "    gpu_usage = []\n",
    "\n",
    "    while not stop_event.is_set():\n",
    "        cpu_usage.append(psutil.cpu_percent(interval=0.1))\n",
    "        try:\n",
    "            gpu_output = subprocess.check_output(['nvidia-smi', '--query-gpu=utilization.gpu', '--format=csv,noheader,nounits'])\n",
    "            gpu_usage.append(int(gpu_output.strip()))\n",
    "        except Exception as e:\n",
    "            gpu_usage.append(None)  # 如果没有GPU或nvidia-smi命令失败，则记录None\n",
    "\n",
    "    # 保存监测结果\n",
    "    thread_output['cpu_usage'] = cpu_usage\n",
    "    thread_output['gpu_usage'] = gpu_usage\n",
    "    print(\"Resource monitoring finished.\")\n",
    "\n",
    "# 运行外部脚本并捕获输出\n",
    "def run_script(stop_event):\n",
    "    try:\n",
    "        with tempfile.NamedTemporaryFile(delete=False) as tmp_file:\n",
    "            process = subprocess.Popen(['/Users/anelloyi/Desktop/run_powermetrics.sh'], stdout=tmp_file, stderr=subprocess.STDOUT, text=True)\n",
    "            print(\"Subprocess started.\")\n",
    "            while not stop_event.is_set():\n",
    "                if process.poll() is not None:  # 检查进程是否已经结束\n",
    "                    break\n",
    "            \n",
    "            if process.poll() is None:\n",
    "                process.terminate()\n",
    "                try:\n",
    "                    process.wait(timeout=0.1)\n",
    "                except subprocess.TimeoutExpired:\n",
    "                    process.kill()\n",
    "                    process.wait()\n",
    "        \n",
    "        with open(tmp_file.name, 'r') as f:\n",
    "            thread_output['powermetrics'] = f.read()\n",
    "        \n",
    "        os.remove(tmp_file.name)  # 删除临时文件\n",
    "        print(\"Subprocess finished.\")\n",
    "    except Exception as e:\n",
    "        thread_output['powermetrics'] = str(e)\n",
    "        print(\"Exception in subprocess:\", str(e))\n",
    "\n",
    "# 创建和启动线程\n",
    "stop_event = threading.Event()\n",
    "\n",
    "\n",
    "# 加载XGBoost模型\n",
    "model = xgb.XGBClassifier()\n",
    "model.load_model('./models_train/imdb_xgboost_model.json')\n",
    "\n",
    "thread1 = threading.Thread(target=save_model, args=(stop_event, model, X_test_tfidf))\n",
    "thread2 = threading.Thread(target=monitor_resources_during_save, args=(stop_event,))\n",
    "thread3 = threading.Thread(target=run_script, args=(stop_event,))\n",
    "thread1.start()\n",
    "thread2.start()\n",
    "thread3.start()\n",
    "\n",
    "# 等待线程完成\n",
    "thread1.join()\n",
    "thread2.join()\n",
    "thread3.join()\n",
    "\n",
    "# 输出从线程收集的数据\n",
    "content = thread_output.get('powermetrics', 'No output captured')\n",
    "# 将内容按行拆分\n",
    "lines = content.split('\\n')\n",
    "# 筛选出以 \"CPU consume\" 和 \"GPU Power\" 开头的行\n",
    "filtered_lines = [line for line in lines if line.startswith('GPU Power:') or line.startswith('CPU Power:')]\n",
    "# 将筛选后的行合并为一个字符串，每行之间用换行符分隔\n",
    "filtered_content = '\\n'.join(filtered_lines)\n",
    "\n",
    "output_file_name = './imbd_models/output_xgboost/output-imdb-xgboost-onnx.txt'\n",
    "with open(output_file_name, 'w') as file:\n",
    "    file.write(filtered_content)\n",
    "    file.write(f'\\nTotal Duration(s): {duration:.2f}')\n",
    "    file.write(f'\\nInference Duration(s): {inference_duration:.4f}')\n",
    "print(f\"Content saved to {output_file_name}\")\n",
    "\n",
    "filtered_lines_count = len(filtered_lines)\n",
    "# print(filtered_lines_count)\n",
    "# print(filtered_lines)\n",
    "\n",
    "duration = inference_duration\n",
    "\n",
    "# 确保 filtered_lines_count 不为零\n",
    "if filtered_lines_count > 0:\n",
    "    # 提取每一个采样点的数字，即CPU和GPU的具体mV\n",
    "    numbers = []\n",
    "    for line in filtered_lines:\n",
    "        match = re.search(r'[\\d.]+', line)\n",
    "        if match:\n",
    "            numbers.append(float(match.group()))\n",
    "\n",
    "    delta_time = duration * 2 / filtered_lines_count\n",
    "    numbers_scaled = [num * delta_time for num in numbers]\n",
    "    total_energy_consumption = sum(numbers_scaled)\n",
    "    print(f\"Total energy consumption: {total_energy_consumption:.2f} mV\")\n",
    "else:\n",
    "    print(\"No filtered lines to process.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### imdb xg pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subprocess started.\n",
      "Time taken to save model: 0.3324 seconds\n",
      "Time taken for inference on 10000 samples: 1.4757 seconds\n",
      "Subprocess finished.\n",
      "Resource monitoring finished.\n",
      "Content saved to ./imbd_models/output_xgboost/output-imdb-xgboost-pth.txt\n",
      "Total energy consumption: 11274.51 mV\n"
     ]
    }
   ],
   "source": [
    "import threading\n",
    "import time\n",
    "import subprocess\n",
    "import tempfile\n",
    "import os\n",
    "import re\n",
    "import psutil\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "import torch\n",
    "import hummingbird.ml\n",
    "from tensorflow.keras.datasets import imdb\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# 初始化全局变量\n",
    "thread_output = {}\n",
    "duration = 0\n",
    "inference_duration = 0\n",
    "\n",
    "# 定义保存模型的函数\n",
    "def save_model(stop_event, model, X_test_tfidf):\n",
    "    global duration\n",
    "    global inference_duration\n",
    "\n",
    "    # 将XGBoost模型转换为PyTorch模型\n",
    "    start_time = time.time()\n",
    "    for i in range(1):\n",
    "        pytorch_model = hummingbird.ml.convert(model, 'pytorch')\n",
    "        # 保存PyTorch模型\n",
    "        torch.save(pytorch_model.model, './imdb_xgboost_model.pth')\n",
    "    end_time = time.time()\n",
    "\n",
    "    duration = end_time - start_time\n",
    "    print(f'Time taken to save model: {duration:.4f} seconds')\n",
    "\n",
    "    # 选择前10000个样本\n",
    "    X_test_sample = X_test_tfidf[:10000]\n",
    "\n",
    "    # 准备输入数据\n",
    "    start_time_inference = time.time()\n",
    "    # 将测试集数据转换为PyTorch张量\n",
    "    X_test_torch = torch.tensor(X_test_sample.toarray(), dtype=torch.float32)\n",
    "\n",
    "    # 批量推理部分\n",
    "    batch_size = 128\n",
    "    num_samples = X_test_torch.shape[0]\n",
    "    num_batches = (num_samples + batch_size - 1) // batch_size\n",
    "\n",
    "    for _ in range(1):  # 推理循环次数为 1\n",
    "        for batch_idx in range(num_batches):\n",
    "            batch_start = batch_idx * batch_size\n",
    "            batch_end = min(batch_start + batch_size, num_samples)\n",
    "            batch = X_test_torch[batch_start:batch_end]\n",
    "            y_pred_torch = pytorch_model.predict(batch)\n",
    "\n",
    "    end_time_inference = time.time()\n",
    "\n",
    "    inference_duration = end_time_inference - start_time_inference\n",
    "    print(f'Time taken for inference on {X_test_torch.shape[0]} samples: {inference_duration:.4f} seconds')\n",
    "\n",
    "    stop_event.set()  # 触发停止其他线程\n",
    "\n",
    "# 监控保存模型时的资源使用率的线程函数\n",
    "def monitor_resources_during_save(stop_event):\n",
    "    cpu_usage = []\n",
    "    gpu_usage = []\n",
    "\n",
    "    while not stop_event.is_set():\n",
    "        cpu_usage.append(psutil.cpu_percent(interval=0.1))\n",
    "        try:\n",
    "            gpu_output = subprocess.check_output(['nvidia-smi', '--query-gpu=utilization.gpu', '--format=csv,noheader,nounits'])\n",
    "            gpu_usage.append(int(gpu_output.strip()))\n",
    "        except Exception as e:\n",
    "            gpu_usage.append(None)  # 如果没有GPU或nvidia-smi命令失败，则记录None\n",
    "\n",
    "    # 保存监测结果\n",
    "    thread_output['cpu_usage'] = cpu_usage\n",
    "    thread_output['gpu_usage'] = gpu_usage\n",
    "    print(\"Resource monitoring finished.\")\n",
    "\n",
    "# 运行外部脚本并捕获输出\n",
    "def run_script(stop_event):\n",
    "    try:\n",
    "        with tempfile.NamedTemporaryFile(delete=False) as tmp_file:\n",
    "            process = subprocess.Popen(['/Users/anelloyi/Desktop/run_powermetrics.sh'], stdout=tmp_file, stderr=subprocess.STDOUT, text=True)\n",
    "            print(\"Subprocess started.\")\n",
    "            while not stop_event.is_set():\n",
    "                if process.poll() is not None:  # 检查进程是否已经结束\n",
    "                    break\n",
    "            \n",
    "            if process.poll() is None:\n",
    "                process.terminate()\n",
    "                try:\n",
    "                    process.wait(timeout=0.1)\n",
    "                except subprocess.TimeoutExpired:\n",
    "                    process.kill()\n",
    "                    process.wait()\n",
    "        \n",
    "        with open(tmp_file.name, 'r') as f:\n",
    "            thread_output['powermetrics'] = f.read()\n",
    "        \n",
    "        os.remove(tmp_file.name)  # 删除临时文件\n",
    "        print(\"Subprocess finished.\")\n",
    "    except Exception as e:\n",
    "        thread_output['powermetrics'] = str(e)\n",
    "        print(\"Exception in subprocess:\", str(e))\n",
    "\n",
    "# 创建和启动线程\n",
    "stop_event = threading.Event()\n",
    "\n",
    "# 加载XGBoost模型\n",
    "model = xgb.XGBClassifier()\n",
    "model.load_model('./models_train/imdb_xgboost_model.json')\n",
    "\n",
    "thread1 = threading.Thread(target=save_model, args=(stop_event, model, X_test_tfidf))\n",
    "thread2 = threading.Thread(target=monitor_resources_during_save, args=(stop_event,))\n",
    "thread3 = threading.Thread(target=run_script, args=(stop_event,))\n",
    "thread1.start()\n",
    "thread2.start()\n",
    "thread3.start()\n",
    "\n",
    "# 等待线程完成\n",
    "thread1.join()\n",
    "thread2.join()\n",
    "thread3.join()\n",
    "\n",
    "# 输出从线程收集的数据\n",
    "content = thread_output.get('powermetrics', 'No output captured')\n",
    "# 将内容按行拆分\n",
    "lines = content.split('\\n')\n",
    "# 筛选出以 \"CPU consume\" 和 \"GPU Power\" 开头的行\n",
    "filtered_lines = [line for line in lines if line.startswith('GPU Power:') or line.startswith('CPU Power:')]\n",
    "# 将筛选后的行合并为一个字符串，每行之间用换行符分隔\n",
    "filtered_content = '\\n'.join(filtered_lines)\n",
    "\n",
    "output_file_name = './imbd_models/output_xgboost/output-imdb-xgboost-pth.txt'\n",
    "with open(output_file_name, 'w') as file:\n",
    "    file.write(filtered_content)\n",
    "    file.write(f'\\nTotal Duration(s): {duration:.2f}')\n",
    "    file.write(f'\\nInference Duration(s): {inference_duration:.4f}')\n",
    "print(f\"Content saved to {output_file_name}\")\n",
    "\n",
    "filtered_lines_count = len(filtered_lines)\n",
    "#print(filtered_lines_count)\n",
    "#print(filtered_lines)\n",
    "\n",
    "duration = inference_duration\n",
    "# 确保 filtered_lines_count 不为零\n",
    "if filtered_lines_count > 0:\n",
    "    # 提取每一个采样点的数字，即CPU和GPU的具体mV\n",
    "    numbers = []\n",
    "    for line in filtered_lines:\n",
    "        match = re.search(r'[\\d.]+', line)\n",
    "        if match:\n",
    "            numbers.append(float(match.group()))\n",
    "\n",
    "    delta_time = duration * 2 / filtered_lines_count\n",
    "    numbers_scaled = [num * delta_time for num in numbers]\n",
    "    total_energy_consumption = sum(numbers_scaled)\n",
    "    print(f\"Total energy consumption: {total_energy_consumption:.2f} mV\")\n",
    "else:\n",
    "    print(\"No filtered lines to process.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.18 ('env_name')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "37cc1b05901c8571bea9fc4b42e3f528ca4394d6e6719f1b5d30d208c4a3cfc1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
